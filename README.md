# James O. Adeshina  
**Data Engineer | AWS | Python | SQL | Airflow | BigQuery**  
MSc Big Data Analytics (Distinction)  

Building scalable, cloud-native data pipelines that transform complex datasets into analytics-ready, production-grade systems.


## About Me

I am a UK-based Data Engineer with hands-on experience designing and deploying cloud-native ETL/ELT pipelines across AWS, BigQuery, and Azure environments.  

My work spans healthcare analytics, public sector automation, fintech-style property data pipelines, and large-scale ML-ready datasets.

I focus on:
- Scalable pipeline design
- Data modelling for analytics
- Data quality & validation
- Cloud architecture
- Business-driven impact

# Selected Data Engineering Case Studies



## 1. Cloud ETL Pipeline for Property Data (AWS + Airflow)

**Problem**  
A property analytics company required automated monthly ingestion of 10,000+ property records to replace manual reporting and inconsistent data processing.

**Solution**  
- Built automated Airflow DAGs for ingestion and orchestration  
- Migrated 5GB+ PostgreSQL data to AWS S3  
- Implemented Bronze-Silver-Gold architecture  
- Applied schema validation & ingestion error checks  
- Registered schemas with AWS Glue  
- Queried via Athena with optimised partitioning  

**Tech Stack**  
Python, SQL, Airflow, AWS S3, Glue, Athena, PostgreSQL, Parquet  

**Impact**  
- Reduced manual reporting workload by ~50%  
- Reduced storage footprint by ~20% using Parquet  
- Achieved 3× faster query performance  
- Prevented ~15% ingestion errors through validation logic  

**Key Engineering Focus**
- Reproducible DAG design  
- Schema evolution handling  
- Storage optimisation  
- Data quality enforcement  

## 2. Public Sector NLP Data Pipeline (Local Authority Project)

**Problem**  
Manual review of 987 community consultation letters required 6–10 hours per batch and limited policy insight extraction.

**Solution**  
Designed a multi-stage automated NLP pipeline that:
- Classified objection vs non-objection letters  
- Extracted issues mapped to five policy areas  
- Performed sentiment analysis  
- Generated summaries at three detail levels  
- Built batch-processing interface for scalable execution  

**Tech Stack**  
Python, NLP workflows, Batch processing architecture, Data structuring, Dashboard integration  

**Impact**  
- Reduced review time to under one minute per 69-letter batch  
- 95% efficiency improvement  
- 97% success rate under stress testing  
- Delivered structured outputs across five insight layers  
- Presented findings to council board members  

**Key Engineering Focus**
- Multi-step pipeline design  
- Structured output generation  
- Batch automation  
- Production-like stress testing  


## 3. Healthcare ML-Ready Data Engineering Pipeline (100k+ Records)

**Problem**  
Raw hospital datasets were fragmented, inconsistent, and unsuitable for modelling.

**Solution**  
- Designed full preprocessing pipeline in Python + SQL  
- Engineered scalable feature pipelines  
- Implemented label encoding and validation logic  
- Built modular training-ready datasets  
- Enforced reproducibility across experiments  

**Tech Stack**  
Python, Pandas, SQL, Scikit-learn, SHAP  

**Impact**  
- Processed 100,000+ records  
- Generated structured ML-ready datasets  
- Enabled explainable AI integration  
- Achieved Distinction-level MSc dissertation  

**Key Engineering Focus**
- Data validation routines  
- Modular pipeline architecture  
- Feature engineering at scale  
- Reproducible dataset generation  


## 4. BigQuery Sentiment Analytics Pipeline (33k+ Reviews)

**Problem**  
Large volumes of app-store reviews required structured ingestion and sentiment extraction for trend analysis.

**Solution**  
- Built Python ingestion pipeline  
- Automated sentiment scoring & keyword extraction  
- Loaded structured outputs into BigQuery  
- Published enriched datasets to Power BI  

**Tech Stack**  
Python, BigQuery, SQL, Power BI  

**Impact**  
- Processed 33,000+ reviews  
- Enabled product trend analysis  
- Built GDPR-compliant structured dataset  



# Architecture Principles

My engineering philosophy:

- Data quality before dashboards  
- Version-controlled pipelines  
- Modular, testable workflow design  
- Cloud-native storage & compute separation  
- Reproducibility across environments  
- Business impact first, tooling second  


# Core Technical Stack

**Languages:** Python, SQL  
**Orchestration:** Airflow  
**Cloud:** AWS (S3, Glue, Athena, Lambda), BigQuery, Azure Synapse  
**Data Modelling:** Star/Snowflake schemas, dimensional modelling  
**Lakehouse:** Delta Lake fundamentals  
**Databases:** PostgreSQL, MySQL, SQL Server  
**Automation & IaC:** CI/CD, Terraform (foundational), Airbyte  
**Data Governance:** GDPR, lineage awareness, access controls  


# Current Focus

I am currently deepening expertise in:
- dbt for analytics engineering  
- Dockerised data workflows  
- CI/CD for data pipelines  
- Infrastructure as Code for reproducible environments  


# Contact

 Email: adeshina413@gmail.com  
 LinkedIn: ([Add your LinkedIn URL](https://www.linkedin.com/in/jamesadeshina/))  

---

> I am actively seeking Data Engineering roles where I can contribute to scalable cloud data platforms and production-grade analytics systems.
